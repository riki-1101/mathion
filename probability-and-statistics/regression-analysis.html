<!DOCTYPE html>
<html lang="ja">
    <head>
        <title>回帰分析</title>
        <meta charset="UTF-8">
        <link rel="stylesheet" href="/math/css/style.css">
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    </head>
    <body>
        <header id="header"></header>
        <main>
            <div id="container">
                <div id="contents">
                    <h1>回帰分析</h1>
                    <div class="article">
                        回帰分析とは、ある特定の変数を他の変数から予測する手法である。予測したい変数を目的変数といい、予測に用いる変数を説明変数という。
                        予測式として線形式を用いる場合を線形回帰といい、非線形な予測式を用いる場合を非線形回帰という。
                    </div>
                    <p></p>
                    <h2>単回帰分析</h2>
                    <div class="article">
                        目的変数 \(y\) の予測に説明変数 \(x\) を用いる。
                        予測式は
                        \[
                        y=ax+b
                        \]
                        \(x_i\) に対する予測値は
                        \[
                        \hat{y_i}=ax_i+b
                        \]
                        と求められる。
                        観測値から予測値を引いたものを残差という。
                        \[
                        \varepsilon_i=y_i-\hat{y_i}=y_i-(ax_i+b)
                        \]
                        各データに対する残差の平方和を最小にすることを考える。
                        \[
                        \mathrm{RSS}=\sum_{i=1}^n\varepsilon_i^2=\sum_{i=1}^n\{y_i-(ax_i+b)\}^2
                        \]
                        これが最小になるように、係数 \(a,b\) の値を求める推定法を最小二乗法という。
                        <p></p>
                        ここで、次の関数を考える。
                        \[
                        E(a,b)=\frac{1}{2}\sum_{i=1}^n(ax_i+b-y_i)^2
                        \]
                        偏微分すると
                        \[
                        \begin{align}
                        \begin{cases}
                        \displaystyle\frac{\partial E}{\partial a}=\sum_{i=1}^nx_i(ax_i+b-y_i)=0\\
                        \displaystyle\frac{\partial E}{\partial a}=\sum_{i=1}^n(ax_i+b-y_i)=0
                        \end{cases}
                        &\Leftrightarrow\begin{cases}
                        a\displaystyle\sum_{i=1}^nx_i^2+b\sum_{i=1}^nx_i=\sum_{i=1}^nx_iy_i\\
                        a\displaystyle\sum_{i=1}^nx_i+bn=\sum_{i=1}^ny_i
                        \end{cases}\\
                        \end{align}
                        \]
                        第２式より
                        \[
                        b=\frac{1}{n}\sum_{i=1}^ny_i-a\cdot\frac{1}{n}\sum_{i=1}^nx_i=\overline{y}-a\overline{x}
                        \]
                        第１式の両辺を \(n\) で割ると
                        \[
                        a\cdot\frac{1}{n}\sum_{i=1}^nx_i^2+b\cdot\frac{1}{n}\sum_{i=1}^nx_i=\frac{1}{n}\sum_{i=1}^nx_iy_i
                        \]
                        \[
                        a\overline{x^2}+b\overline{x}=\overline{xy}
                        \]
                        これに \(b=\overline{y}-a\overline{x}\) を代入して
                        \[
                        a\overline{x^2}+(\overline{y}-a\overline{x})\overline{x}=\overline{xy}
                        \]
                        \[
                        a\{\overline{x^2}-(\overline{x})^2\}=\overline{xy}-\overline{x}\cdot\overline{y}
                        \]
                        よって
                        \[
                        a=\frac{\overline{xy}-\overline{x}\cdot\overline{y}}{\overline{x^2}-(\overline{x})^2},~~~~~b=\overline{y}- \frac{\overline{xy}-\overline{x}\cdot\overline{y}}{\overline{x^2}-(\overline{x})^2} \overline{x}
                        \]
                    </div>
                    <p></p>
                    <h2>重回帰分析</h2>
                    <div class="article">
                        複数の説明変数を使って１つの目的変数を予測する回帰分析の手法を重回帰分析という。
                        <p></p>
                        説明変数 \(x_1,x_2,\cdots,x_p\)
                        <p></p>
                        <table border="1">
                            <tr><th>          </th><th>\(y\)     </th><th>\(x_1\)   </th><th>\(x_2\)   </th><th>\(\cdots\)</th><th>\(x_p\)   </th></tr>
                            <tr><td>1         </td><td>\(y_1\)   </td><td>\(x_{11}\)</td><td>\(x_{12}\)</td><td>\(\cdots\)</td><td>\(x_{1p}\)</td></tr>
                            <tr><td>2         </td><td>\(y_2\)   </td><td>\(x_{21}\)</td><td>\(x_{22}\)</td><td>\(\cdots\)</td><td>\(x_{2p}\)</td></tr>
                            <tr><td>\(\vdots\)</td><td>\(\vdots\)</td><td>\(\vdots\)</td><td>\(\vdots\)</td><td>\(\ddots\)</td><td>\(\vdots\)</td></tr>
                            <tr><td>n         </td><td>\(y_n\)   </td><td>\(x_{n1}\)</td><td>\(x_{n2}\)</td><td>\(\cdots\)</td><td>\(x_{np}\)</td></tr>
                        </table>
                        <p></p>
                        回帰式は
                        \[
                        y=\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_px_p
                        \]
                        と表され、\(\beta_0,\beta_1,\cdots,\beta_p\) は偏回帰係数と呼ばれる。
                        <p></p>
                        \[
                        X=
                        \begin{bmatrix}
                        1 & x_{11} & x_{12} & \cdots & x_{1p}\\
                        1 & x_{21} & x_{22} & \cdots & x_{2p}\\
                        \vdots & \vdots & \vdots & \ddots & \vdots\\
                        1 & x_{n1} & x_{n2} & \cdots & x_{np}\\
                        \end{bmatrix}
                        \]
                    </div>
                    <p></p>
                    <a href="javascript:history.back();" class="back">戻る</a>
                </div>
                <div id="side-menu"></div>
            </div>
        </main>
        <footer id="footer"></footer>
        <script src="/math/js/header.js"></script>
        <script src="/math/js/footer.js"></script>
        <script src="/math/js/side-menu.js"></script>
    </body>
</html>